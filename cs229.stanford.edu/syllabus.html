<!DOCTYPE html>
<html lang="en">
  <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!-- <meta http-equiv="X-UA-Compatible" content="IE=edge"> -->
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->
  <title>CS229: Machine Learning</title>

  <!-- bootstrap -->
  <!-- <link rel="stylesheet" href="./style/bootstrap.min.css"> -->
  <link rel="stylesheet" href="../maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
  <link rel="stylesheet" href="style/bootstrap-theme.min.css">
  <link href="style/newstyle.css" rel="stylesheet" type="text/css">
  <body>
  <nav class="navbar navbar-expand-md navbar-dark">
    <a href="index.html">
    <img src="static/seal-dark-red.png" style="height:40px; float: left; margin-left: 20px; margin-right: 20px;"></a>
    <a class="navbar-brand" href="index.html">CS 229</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarsExampleDefault" aria-controls="navbarsExampleDefault" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarsExampleDefault">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item"><a class="nav-link" href="syllabus.html#schedule">Schedule</a></li>
        <li class="nav-item"><a class="nav-link" href="syllabus.html#opt">Supplementary Materials</a></li>
      </ul>
    </div>
  </nav>


<div class="sechighlight">
<div class="container sec" style="margin-top: 1em">
  <h2>Syllabus and Course Schedule</h2>
  <p>
  <b>Time and Location</b>:
  Monday, Wednesday 9:30-10:50am, <a href="../web.stanford.edu/dept/HPS/CubberleyDirections.html">Nvidia Auditorium</a><br />
  <strong>Class Videos</strong>:
    Current quarter's class videos are available <a href="../scpd.stanford.edu/index.html">here</a> for SCPD students and <a href="../mvideox.stanford.edu/index.html">here</a> for non-SCPD students.</p>
<br>
</div>
</div>


<div class="container">
<table id="schedule" class="table table-bordered no-more-tables">
  <thead class="active" style="background-color:#f9f9f9">
    <th>Event</th><th>Date</th><th>Description</th><th>Materials and Assignments</th>
  </thead>

  <tbody>
  <tr>
    <td>Lecture&nbsp;1</td>
    <td> 9/25 </td>
    <td><strong>Introduction</strong> (1 class)
      <ol>
      <li>Basic concepts</li>
      </ol>
    </td>
    <td>
      <strong>Class Notes</strong>
      <ul>
      <li>Supervised Learning, Discriminative Algorithms [<a href="notes/cs229-notes1.ps">ps</a>] [<a href="notes/cs229-notes1.pdf">pdf</a>] </li>
      </ul>

      <strong>Problem Set 0</strong> <em>Will be posted soon</em>. <a href="gradescope.html">Submission instructions</a>.
    </td>
  </tr>

   <tr>
    <td>Lecture&nbsp;2</td>
    <td> 9/27 </td>
    <td rowspan="5">
      <strong>Supervised learning</strong> (5 classes)
                 <ol>
                  <li>Supervised learning setup.  LMS.</li>
                  <li>Logistic regression.  Perceptron.  Exponential family.  </li>
                  <li>Generative learning algorithms. Gaussian discriminant analysis.  Naive Bayes. </li>
                  <li>Support vector machines.  </li>
                  <li>Model selection and feature selection. </li>
                  <li>Ensemble methods: Bagging, boosting.  </li>
                  <li>Evaluating and debugging learning algorithms. </li>
                </ol>
            </td>
    <td rowspan="5">
      <strong>Class Notes</strong>
      <ul>
      <li>Generative Algorithms [<a href="notes/cs229-notes2.ps">ps</a>] [<a href="notes/cs229-notes2.pdf">pdf</a>] </li>
      <li>Support Vector Machines [<a href="notes/cs229-notes3.ps">ps</a>] [<a href="notes/cs229-notes3.pdf">pdf</a>] </li>
      </ul>

      <strong>Problem Set 1</strong> Out 10/4. Due 10/18.
    </td>
  </tr>

  <tr>
    <td>Lecture&nbsp;3</td>
    <td> 10/2 </td>
    <!-- <td></td> -->
    <!-- <td>    </td> -->
  </tr>

  <tr>
    <td>Lecture&nbsp;4</td>
    <td> 10/4 </td>
    <!-- <td></td> -->
    <!-- <td>    </td> -->
  </tr>

  <tr>
    <td>Lecture&nbsp;5</td>
    <td> 10/9 </td>
    <!-- <td></td> -->
    <!-- <td>    </td> -->
  </tr>

  <tr>
    <td>Lecture&nbsp;6</td>
    <td> 10/11 </td>
    <!-- <td></td> -->
    <!-- <td>    </td> -->
  </tr>



  <tr>
    <td>Lecture&nbsp;7</td>
    <td> 10/16 </td>
    <td rowspan="2">
      <strong>Learning theory</strong> (2 classes)
      <ol><li>Bias/variance tradeoff</li></ol>
    </td>
    <td rowspan="2">
    <strong>Class Notes</strong>
    <ul>
      <li>Learning Theory [<a href="notes/cs229-notes4.ps">ps</a>] [<a href="notes/cs229-notes4.pdf">pdf</a>]</li>
      <li>Regularization and Model Selection [<a href="notes/cs229-notes5.ps">ps</a>] [<a href="notes/cs229-notes5.pdf">pdf</a>] </li>
      <li>Online Learning and the Perceptron Algorithm. (optional reading) [<a href="notes/cs229-notes6.ps">ps</a>] [<a href="notes/cs229-notes6.pdf">pdf</a>] </li>
    </ul>

      <strong>Problem Set 2</strong> Out 10/18. Due 11/1.
  </td>
  </tr>

  <tr>
    <td>Lecture&nbsp;8 </td>
    <td> 10/18 </td>
    <!-- <td></td> -->
    <!-- <td></td> -->
  </tr>

  <tr>
    <td>Project</td>
    <td> 10/20 </td>
     <td colspan="2">Project proposal due at <strong>11:59pm</strong>.</td>
  </tr>

  <tr>
    <td>Lecture&nbsp;9 </td>
    <td>10/23</td>
    <td rowspan="5"><strong>Unsupervised learning</strong> (5 classes)
      <ol>
        <li>Clustering. K-means. </li>
        <li>EM. Mixture of Gaussians. </li>
        <li>Factor analysis. </li>
        <li>PCA (Principal components analysis).</li>
        <li>ICA (Independent components analysis).</li>
      </ol>
    </td>
    <td rowspan="5">
      <strong>Class Notes</strong>
      <ul>
      <li>Unsupervised Learning, k-means clustering. [<a href="notes/cs229-notes7a.ps">ps</a>] [<a href="notes/cs229-notes7a.pdf">pdf</a>]</li>
      <li>Mixture of Gaussians [<a href="notes/cs229-notes7b.ps">ps</a>] [<a href="notes/cs229-notes7b.pdf">pdf</a>] </li>
      <li>The EM Algorithm [<a href="notes/cs229-notes8.ps">ps</a>] [<a href="notes/cs229-notes8.pdf">pdf</a>] </li>
      <li>Factor Analysis [<a href="notes/cs229-notes9.ps">ps</a>] [<a href="notes/cs229-notes9.pdf">pdf</a>]</li>
      <li>Principal Components Analysis [<a href="notes/cs229-notes10.ps">ps</a>] [<a href="notes/cs229-notes10.pdf">pdf</a>] </li>
      <li>Independent Components Analysis [<a href="notes/cs229-notes11.ps">ps</a>] [<a href="notes/cs229-notes11.pdf">pdf</a>] </li>
    </ul>

      <strong>Problem Set 3</strong> Out 11/1. Due 11/15.
    </td>
  </tr>

  <tr>
    <td>Lecture&nbsp;10</td>
    <td>10/25</td>
    <!-- <td></td> -->
    <!-- <td>    </td> -->
  </tr>

  <tr>
    <td>Lecture&nbsp;11</td>
    <td> 10/30 </td>
    <!-- <td></td> -->
    <!-- <td></td> -->
  </tr>
  <tr>
    <td>Lecture&nbsp;12</td>
    <td> 11/1 </td>
    <!-- <td></td> -->
    <!-- <td></td> -->
  </tr>

  <tr>
    <td>Lecture&nbsp;12</td>
    <td> 11/6</td>
    <!-- <td></td> -->
    <!-- <td></td> -->
  </tr>

  <tr>
    <td>Midterm</td>
    <td>11/8</td>
    <td colspan="2">
      <span style="text-align: left;">The midterm is <b>open-book/open-notes/open laptop (no internet)</b>. It will take place on <b>Wednesday, November 8, 2017 from 6-9 PM</b>.  The course staff will announce exam venue and material covered closer to the midterm date.</span>
    </td>
  </tr>

  <tr>
    <td>Project</td>
    <td> 11/17 </td>
     <td colspan="2">Project milestones due 11/17 at <strong>5pm</strong>.</td>
  </tr>

  <tr>
    <td>Lecture&nbsp;12 </td>
    <td> 11/13 </td>
    <td rowspan="4"><strong>Reinforcement learning and control</strong> (4 classes)
      <ol>
        <li>MDPs. Bellman equations. </li>
        <li>Value iteration and policy iteration. </li>
        <li>Linear quadratic regulation (LQR). LQG.</li>
        <li>Q-learning. Value function approximation. </li>
        <li>Policy search. Reinforce. POMDPs. </li>
      </ol>
    </td>
    <td rowspan="4">
     <strong>Class Notes</strong>
     <ul>
      <li>Reinforcement Learning and Control [<a href="notes/cs229-notes12.ps">ps</a>] [<a href="notes/cs229-notes12.pdf">pdf</a>]</li>
    </ul>

      <strong>Problem Set 4</strong> Out 11/15. Due 12/6.
    </td>
  </tr>

  <tr>
    <td>Lecture&nbsp;13</td>
    <td> 11/15 </td>
    <!-- <td></td> -->
    <!-- <td>    </td> -->
  </tr>

  <tr>
    <td>Lecture&nbsp;14</td>
    <td> 11/27 </td>
    <!-- <td></td> -->
    <!-- <td></td> -->
  </tr>

  <tr>
    <td>Lecture&nbsp;16</td>
    <td> 11/29 </td>
    <!-- <td></td> -->
    <!-- <td>  </td> -->
  </tr>

  <tr>
    <td>Lecture&nbsp;17</td>
    <td>12/4</td>
    <td rowspan="3"><strong>Deep Learning</strong> (3 classes)
      <ol>
        <li>NN architecture</li>
        <li>Forward/Back propagation</li>
        <li>Vectorization </li>
        <li>Adversarial</li>
      </ol>
    </td>
    <td rowspan="3">
    <strong>Class Notes</strong>
    <ul>
    <li>To be announced.</li>
    </ul>
    </td>
  </tr>

  <tr>
    <td>Lecture&nbsp;18</td>
    <td>12/6</td>
    <!-- <td></td> -->
    <!-- <td>    </td> -->
  </tr>

  <tr>
    <td>Lecture&nbsp;19</td>
    <td> TBD </td>
    <!-- <td></td> -->
    <!-- <td>    </td> -->
  </tr>

  <tr>
    <td>Project</td>
    <td> 12/12 </td>
     <td colspan="2"> Poster presentations from 8:30-11:30am.  Venue and details to be announced.</td>
  </tr>

  <tr>
    <td>Project</td>
    <td> 12/15 </td>
     <td colspan="2">Final writeup due at <strong>11:59pm</strong> (no late days).</td>
  </tr>

  <tr class="warning" id="opt">
    <td colspan="4">
    <b>Supplementary Notes</b>
    <ol>
      <li>Binary classification with +/-1 labels [<a href="extra-notes/loss-functions.pdf">pdf</a>]</li>
      <li>Boosting algorithms and weak learning [<a href="extra-notes/boosting.pdf">pdf</a>] </li>
      <li>Functional after implementing stump_booster.m in PS2. [<a href="extra-notes/boosting_example.m">here</a>] </li>
      <li>The representer theorem [<a href="extra-notes/representer-function.pdf">pdf</a>]</li>
      <li>Hoeffding's inequality [<a href="extra-notes/hoeffding.pdf">pdf</a>] </li>
    </ol></td>
  </tr>

  <tr class="alert">
    <td colspan="4">
    <b>Section Notes</b>
    <ol>
      <li>Linear Algebra Review and Reference [<a href="section/cs229-linalg.pdf">pdf</a>]</li>
      <li>Probability Theory Review [<a href="section/cs229-prob.pdf">pdf</a>] </li>
      <li>Files for the Matlab tutorial:  [<a href="materials/MATLAB_Session.pdf">pdf</a>] [<a href="section/matlab/sigmoid.m">sigmoid.m</a>] [<a href="section/matlab/logistic_grad_ascent.m">logistic_grad_ascent.m</a>] [<a href="materials/matlab_session.m">matlab_session.m</a>] </li>
      <li>Convex Optimization Overview, Part I [<a href="section/cs229-cvxopt.ps">ps</a>] [<a href="section/cs229-cvxopt.pdf">pdf</a>]</li>
      <li>Convex Optimization Overview, Part II [<a href="section/cs229-cvxopt2.ps">ps</a>] [<a href="section/cs229-cvxopt2.pdf">pdf</a>] </li>
      <li>Hidden Markov Models [<a href="section/cs229-hmm.ps">ps</a>] [<a href="section/cs229-hmm.pdf">pdf</a>] </li>
      <li>The Multivariate Gaussian Distribution [<a href="section/gaussians.pdf">pdf</a>] </li>
      <li>More on Gaussian Distribution [<a href="section/more_on_gaussians.pdf">pdf</a>] </li>
      <li>Gaussian Processes [<a href="section/cs229-gaussian_processes.pdf">pdf</a>] </li>
    </ol></td>
  </tr>
  <tr>
    <td colspan="4">
      <b>Other Resources</b>
      <ol>
        <li>Advice on applying machine learning: Slides from Andrew's lecture on getting machine learning algorithms to work in practice can be found <a href="materials/ML-advice.pdf">here</a>.<br></li>
        <li>Previous projects: A list of last year's final projects can be found <a href="projects2016.html">here</a>.<br></li>
        <li>Matlab resources: Here are a couple of Matlab tutorials that you might find helpful: <a href="../www.math.ucsd.edu/~bdriver/21d-s99/matlab-primer.html">http://www.math.ucsd.edu/~bdriver/21d-s99/matlab-primer.html</a> and <a href="../www.math.mtu.edu/~msgocken/intro/node1.html">http://www.math.mtu.edu/~msgocken/intro/node1.html</a>. For emacs users only: If you plan to run Matlab in emacs, here are <a href="materials/matlab.el">matlab.el</a>, and a helpful <a href="materials/emacs">.emac's</a> file.<br></li>
        <li>Octave resources: For a free alternative to Matlab, check out <a href="../www.gnu.org/software/octave/index.html">GNU Octave</a>. The official documentation is available <a href="../www.gnu.org/software/octave/doc/interpreter/index.html">here</a>. Some useful tutorials on Octave include <a href="http://en.wikibooks.org/wiki/Octave_Programming_Tutorial">http://en.wikibooks.org/wiki/Octave_Programming_Tutorial</a> and <a href="../www-mdp.eng.cam.ac.uk/web/CD/engapps/octave/octavetut.pdf">http://www-mdp.eng.cam.ac.uk/web/CD/engapps/octave/octavetut.pdf</a> .<br></li>
        <li>Data: Here is the <a href="../www.ics.uci.edu/~mlearn/MLRepository.html">UCI Machine learning repository</a>, which contains a large collection of standard datasets for testing learning algorithms. If you want to see examples of recent work in machine learning, start by taking a look at the conferences <a href="../www.nips.cc/index.html">NIPS</a>(all old NIPS papers are online) and ICML. Some other related conferences include UAI, AAAI, IJCAI.<br></li>
        <li>Viewing PostScript and PDF files: Depending on the computer you are using, you may be able to download a <a href="../www.cs.wisc.edu/~ghost/index.html">PostScript</a> viewer or <a href="../www.adobe.com/products/acrobat/readstep2_allversions.html">PDF viewer</a> for it if you don't already have one.<br></li>
      </ol>
    </td>
  </tr>

</tbody></table>
</div>

</body></html>
