{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"taller01.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"y0V5tYC9o4RP","colab_type":"text"},"cell_type":"markdown","source":["# Visión Artificial con Redes Neuronales Profundas\n","\n","*   Alfredo Cuesta\n","*   Juan José Pantrigo"]},{"metadata":{"id":"K4TQmq3hw4AO","colab_type":"text"},"cell_type":"markdown","source":["## ¿Qué somos capaces de hacer?\n","\n","* Detección y segmentación:  https://www.youtube.com/watch?v=OOT3UIXZztE\n","* Generación de imágenes: https://www.youtube.com/watch?v=JzgOfISLNjk\n","* Estimación de pose 3D a partir de imágenes 2D\n","\n","\n","\n"]},{"metadata":{"id":"HQTjz9pomZq-","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"LNVUNHmTnZBA","colab_type":"text"},"cell_type":"markdown","source":["## ¿Cómo se hace?\n","\n","*  Modelo computacional por capas\n","* Cada capa procesa la salida de la capa anterior\n","* El procesado consiste en:\n","\n",">1. Aplicar filtros de convolución para resaltar características visuales (bordes, esquinas, etc)\n",">1. Agrupar los píxeles más resaltados $\\rightarrow$ reducción de tamaño\n","\n","* Tras varias capas, combinar los pixels resultantes para **aprender a realizar la tarea**"]},{"metadata":{"id":"XzysoBE72PWN","colab_type":"text"},"cell_type":"markdown","source":["## ¿Cómo puede aprender una máquina?\n","* Depende de la tarea\n","* Un caso sencillo: reconocer señales de tráfico \n","\n","  https://youtu.be/5ZQPbMyywvM\n","  \n","* Ingredientes:\n","> * Conjunto con (muchas) imágenes, $X$\n","> * Cada imagen debe tener asociada una etiqueta, $Y$\n","* Receta:\n","> * Introducir una imagen $x$ en la máquina\n","> * La máquina hace una predicción sobre la etiqueta de la imagen, $\\hat{y}$\n",">* Medimos el error o pérdida (loss), $L = (y-\\hat{y})^2$\n",">* Ajustamos los parámetros de la máquina para reducir el error \n",">* Volver a empezar con otro ejemplo"]},{"metadata":{"id":"QDdx_RjinYOq","colab_type":"text"},"cell_type":"markdown","source":["## ¿Puedo hacerlo yo también?\n","* ¡¡ Software libre !!\n","  * Python\n","  * Keras\n","  * Tensorflow\n","  * GitHub\n","    ...\n","  \n","* PERO, en general, hace falta potencia computacional (GPU NVIDIA)\n","\n","  $\\rightarrow$ Con Google Colab se pueden aprender muchas técnicas (empleado en el MOVA-URJC)\n"]},{"metadata":{"id":"D9q8_vBv8WLq","colab_type":"text"},"cell_type":"markdown","source":["## Manos a la obra\n","\n","Vamos a reconocer dígitos manuscritos utilizando el conjunto de datos MNIST \n","\n","https://en.wikipedia.org/wiki/MNIST_database"]},{"metadata":{"id":"Jk8gq6jUXl_D","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"d84e026c-f3e2-4ef3-c8ae-a6ea33d5a65e","executionInfo":{"status":"ok","timestamp":1552567469587,"user_tz":-60,"elapsed":2522,"user":{"displayName":"ShuXiang Gao","photoUrl":"","userId":"03389382790984451718"}}},"cell_type":"code","source":["#*********************\n","#  Importar módulos \n","#*********************\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, Activation, Dropout\n","from keras.models import Model\n","from keras.utils import to_categorical\n","\n","#*********************\n","# Variables globales \n","#*********************\n","num_classes = 10 # Núm. de clases o etiquetas diferentes\n","N_epochs = 2     # Num. de veces que utilizamos el conjunto de datos\n","batch_size = 64  # Núm. de imágenes que usamos para ajustar la red en cada paso\n","\n","#************************************\n","# Cargar el conjunto de datos MNIST\n","#************************************\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","#- x_train: imágenes para que la red aprenda\n","#- y_train: etiqueta de cada imagen\n","#- x_test:  imágenes para probar la red\n","#- y_test:  etiqueta de cada imagen"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"metadata":{"id":"UjdQjpAnZIRQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"059a5eba-bcd6-4dba-f3bb-2ffd716d1ca7","executionInfo":{"status":"ok","timestamp":1552567923972,"user_tz":-60,"elapsed":545,"user":{"displayName":"ShuXiang Gao","photoUrl":"","userId":"03389382790984451718"}}},"cell_type":"code","source":["# ¡¡ Es importante conocer como son los datos !!\n","#  por ej. ¿¿ Qué dimensiones tienen ??\n","\n","N_train,W,H = x_train.shape\n","N_test, W,H  = x_test.shape\n","\n","print(\"Dims. del conjunto de entrenamiento:\",N_train, W, H)\n","print(\"Dims. del conjunto de prueba (test):\",N_test,  W, H)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Dims. del conjunto de entrenamiento: 60000 28 28\n","Dims. del conjunto de prueba (test): 10000 28 28\n"],"name":"stdout"}]},{"metadata":{"id":"Qm8vni7pZkJk","colab_type":"code","colab":{}},"cell_type":"code","source":["# También es importante preparar los datos para poder procesarlos:\n","\n","# 1) Las imágenes deben tener 4 dimensiones: \n","#     Núm.imagnes, Ancho(W), Alto(H), Profundidad de color (D)\n","\n","D=1 #<- Las imagenes de este ejemplo son en 'escala de grises' \n","x_input = x_train.reshape((N_train,W,H,D)) \n","\n","# 2) Las etiquetas (1,2,3....) deben tener formato 'one-hot'\n","\n","y_1hot = to_categorical(y_train, num_classes=num_classes)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dLxFZm9vK9cl","colab_type":"code","colab":{}},"cell_type":"code","source":["#***********************************\n","# Construcción de la red neuronal \n","#***********************************\n","\n","#-- Tamaño de los filtros de convolucion\n","N = 3\n","#-- Agrupamiento\n","S = 2\n","#-- Neuronas lineales para estimar la etiqueta\n","M = 32\n","\n","#== Capa de entrada ================\n","x = Input(shape=(W,H,D))\n","\n","#== Capa Convolucional =============\n","h1 = Conv2D(16, (N, N), activation='relu', padding='same')(x)\n","#== Capa de agrupamiento ===========\n","h2 = MaxPooling2D((S, S))(h1)\n","#== Capa Convolucional =============\n","h3 = Conv2D(32, (N, N), activation='relu', padding='same')(h2)\n","#== Capa de agrupamiento ===========\n","h4 = MaxPooling2D((S, S))(h3)\n","#== Capa Convolucional =============\n","h5 = Conv2D(64, (N, N), activation='relu', padding='same')(h4)\n","#== Capa de agrupamiento ===========\n","h6 = MaxPooling2D((S, S))(h5)\n","#== Combinar los pixels resultantes\n","h7 = Flatten()(h6)\n","h8 = Dense(M, activation='relu')(h7)\n","\n","#== Producir una salida ============\n","yhat = Dense(num_classes, activation='softmax')(h8)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qHMx_h32PPhR","colab_type":"code","colab":{}},"cell_type":"code","source":["#*******************************\n","# Crear el 'objeto' CNN \n","#  y añadir \n","#  - mecánismo para optimizar\n","#  - funcion de pérdida\n","#*******************************\n","CNN = Model(x,yhat)\n","CNN.compile(optimizer='adam', loss='categorical_crossentropy')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AUi5gjCQQQj2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"outputId":"1fd6b771-f01c-4b7b-89f7-209b7cc1ffd0","executionInfo":{"status":"ok","timestamp":1552568478977,"user_tz":-60,"elapsed":23588,"user":{"displayName":"ShuXiang Gao","photoUrl":"","userId":"03389382790984451718"}}},"cell_type":"code","source":["#*********************\n","#  ¡¡ APRENDEMOS !!\n","#*********************\n","\n","CNN.fit(x_input, y_1hot, epochs=N_epochs, batch_size=batch_size)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/2\n","60000/60000 [==============================] - 14s 227us/step - loss: 0.3808\n","Epoch 2/2\n","60000/60000 [==============================] - 9s 147us/step - loss: 0.0721\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f56ae12c898>"]},"metadata":{"tags":[]},"execution_count":16}]},{"metadata":{"id":"TMnTymQ5bfy2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":398},"outputId":"4b02a00d-3e73-4c0c-9524-89a5c8d0cdb4","executionInfo":{"status":"ok","timestamp":1552568485863,"user_tz":-60,"elapsed":1356,"user":{"displayName":"ShuXiang Gao","photoUrl":"","userId":"03389382790984451718"}}},"cell_type":"code","source":["#************************************\n","#      ¿Qué tal ha funcionado?\n","#  ¿¿Qué hará con ejemplos nuevos??\n","#************************************\n","\n","# Recordad que los datos deben tener 4 dims.\n","x_nuevos = x_test.reshape((N_test,W,H,D)) \n","\n","# Vamos a ver que dice la CNN sobre estos ejemplos:\n","prediccion_etiqueta = CNN.predict(x_nuevos)\n","\n","# Pero...¿Qué tal funciona con la K-ésima imagen de prueba (test)?\n","k = 9999 #<-- elegir un número entre 0 y 9999\n","print(y_test[k] ,'<-- etiqueta real')\n","print(np.argmax(prediccion_etiqueta[k,:]) ,'<-- etiqueta predicha')\n","plt.imshow(x_test[k,:,:])"],"execution_count":17,"outputs":[{"output_type":"stream","text":["6 <-- etiqueta real\n","6 <-- etiqueta predicha\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f56a5a8f748>"]},"metadata":{"tags":[]},"execution_count":17},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBoQlABgQlgBg8H9awp4els/WDAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 576x396 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"1lVFqGScpBFh","colab_type":"text"},"cell_type":"markdown","source":["## Esperamos que os haya gustado :)\n","\n","### Enlaces interesantes\n","* Tensorflow Playground: https://playground.tensorflow.org\n","* Para dibujar redes neuronales: http://alexlenail.me/NN-SVG/AlexNet.html \n","* DeepLearning.ai: https://www.youtube.com/channel/UCcIXc5mJsHVYTZR1maL5l9w\n","\n","Si quieres continuar tu formación en la URJC.\n","* Master Oficial en Visión Artificial URJC: https://mastervisionartificial.es/\n","\n","Más sobre nosotros:\n","* Grupo de Computación de Altas Prestaciones y Optimización (CAPO): http://www.caporesearch.es\n","* Prof. Juan José Pantrigo: http://www.caporesearch.es/jjpantrigo\n","* Prof. Alfredo Cuesta: http://www.caporesearch.es/acuesta\n","\n","# GRACIAS POR VENIR"]}]}